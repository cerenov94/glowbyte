{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import DirectoryLoader,PyPDFLoader\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display, Markdown\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset,Dataset\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'llama3.1'\n",
    "llm = ChatOllama(model=model_name,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(\n",
    "    [\"llm-math\",\"wikipedia\"], \n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent for math calculation and wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'Who is Petr the Great?'\n",
    "handler = StdOutCallbackHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cerenov/anaconda3/envs/lchain/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Thought: I think there might be some confusion with the name. Petr the Great is actually known as Peter the Great in English, so let me try searching again.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some confusion with the name. Petr the Great is actually known as Peter the Great in English, so let me try searching again.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Thought: I think there might be some spelling mistake in the name. Let me try searching again with a slight variation.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great Russian tsar\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some confusion with the name. Petr the Great is actually known as Peter the Great in English, so let me try searching again.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some spelling mistake in the name. Let me try searching again with a slight variation.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great Russian tsar\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Question: Who is Petr the Great?\n",
      "Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some confusion with the name. Petr the Great is actually known as Peter the Great in English, so let me try searching again.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some spelling mistake in the name. Let me try searching again with a slight variation.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great Russian tsar\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Question: Who is Petr the Great?\n",
      "Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some confusion with the name. Petr the Great is actually known as Peter the Great in English, so let me try searching again.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some spelling mistake in the name. Let me try searching again with a slight variation.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great Russian tsar\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Question: Who is Petr the Great?\n",
      "Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some confusion with the name. Petr the Great is actually known as Peter the Great in English, so let me try searching again.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some spelling mistake in the name. Let me try searching again with a slight variation.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great Russian tsar\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Question: Who is Petr the Great?\n",
      "Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some confusion with the name. Petr the Great is actually known as Peter the Great in English, so let me try searching again.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some spelling mistake in the name. Let me try searching again with a slight variation.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great Russian tsar\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Question: Who is Petr the Great?\n",
      "Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some confusion with the name. Petr the Great is actually known as Peter the Great in English, so let me try searching again.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some spelling mistake in the name. Let me try searching again with a slight variation.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great Russian tsar\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Question: Who is Petr the Great?\n",
      "Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some confusion with the name. Petr the Great is actually known as Peter the Great in English, so let me try searching again.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some spelling mistake in the name. Let me try searching again with a slight variation.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great Russian tsar\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Question: Who is Petr the Great?\n",
      "Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some confusion with the name. Petr the Great is actually known as Peter the Great in English, so let me try searching again.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some spelling mistake in the name. Let me try searching again with a slight variation.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great Russian tsar\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Question: Who is Petr the Great?\n",
      "Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some confusion with the name. Petr the Great is actually known as Peter the Great in English, so let me try searching again.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some spelling mistake in the name. Let me try searching again with a slight variation.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great Russian tsar\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Question: Who is Petr the Great?\n",
      "Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some confusion with the name. Petr the Great is actually known as Peter the Great in English, so let me try searching again.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some spelling mistake in the name. Let me try searching again with a slight variation.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great Russian tsar\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Question: Who is Petr the Great?\n",
      "Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some confusion with the name. Petr the Great is actually known as Peter the Great in English, so let me try searching again.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some spelling mistake in the name. Let me try searching again with a slight variation.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great Russian tsar\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Question: Who is Petr the Great?\n",
      "Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Calculator, wikipedia\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
      "Human: Who is Petr the Great?\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Petr the Great\"\n",
      "}\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some confusion with the name. Petr the Great is actually known as Peter the Great in English, so let me try searching again.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I think there might be some spelling mistake in the name. Let me try searching again with a slight variation.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great Russian tsar\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Question: Who is Petr the Great?\n",
      "Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:Could not parse LLM output: Thought: I've tried searching with different variations of the name, but still couldn't get a valid response. Let me try again with a simple search.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Thought: This seems like a historical figure, so it would be best to look up information about them on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Peter the Great\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer = agent({'input':q},callbacks=[handler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent with python tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_python_agent(\n",
    "    llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True,\n",
    "    max_execution_time=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cerenov/anaconda3/envs/lchain/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Use Python_REPL\n",
      "Action Input: `print([''.join(s) for s in [[\"leet\",\"code\"]]])\u001b[0m\n",
      "Observation: Use Python_REPL is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's my revised response:\n",
      "\n",
      "Question: You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.\n",
      "Thought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: `print(''.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mleetcode\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's my revised response:\n",
      "\n",
      "Question: You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.\n",
      "Thought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: `print(''.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mleetcode\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's my revised response:\n",
      "\n",
      "Question: You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.\n",
      "Thought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: `print(''.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSyntaxError(\"'(' was never closed\", ('<string>', 1, 14, 'print(\\'\\'.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist\\n', 1, 0))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's my revised response:\n",
      "\n",
      "Question: You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.\n",
      "Thought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: `print(''.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mleetcode\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's my revised response:\n",
      "\n",
      "Question: You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.\n",
      "Thought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: `print(''.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSyntaxError(\"'(' was never closed\", ('<string>', 1, 14, 'print(\\'\\'.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist\\n', 1, 0))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's my revised response:\n",
      "\n",
      "Question: You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.\n",
      "Thought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: `print(''.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mleetcode\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's my revised response:\n",
      "\n",
      "Question: You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.\n",
      "Thought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: `print(''.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mleetcode\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's my revised response:\n",
      "\n",
      "Question: You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.\n",
      "Thought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: `print(''.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mleetcode\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's my revised response:\n",
      "\n",
      "Question: You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.\n",
      "Thought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: `print(''.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSyntaxError(\"'(' was never closed\", ('<string>', 1, 14, 'print(\\'\\'.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist\\n', 1, 0))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.\n",
      "Thought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: `print(''.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSyntaxError(\"'(' was never closed\", ('<string>', 1, 14, 'print(\\'\\'.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist\\n', 1, 0))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.\n",
      "Thought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: `print(''.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSyntaxError(\"'(' was never closed\", ('<string>', 1, 14, 'print(\\'\\'.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist\\n', 1, 0))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.\n",
      "Thought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: `print(''.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSyntaxError(\"'(' was never closed\", ('<string>', 1, 14, 'print(\\'\\'.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist\\n', 1, 0))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.\n",
      "Thought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: `print(''.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSyntaxError(\"'(' was never closed\", ('<string>', 1, 14, 'print(\\'\\'.join(s for sublist in [[\"leet\",\"code\"]] for s in sublist\\n', 1, 0))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.\n",
      "Thought: To concatenate a list of strings in Python, I can use the `join()` function. However, since the list contains lists themselves, I need to first flatten the inner lists.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: `print(''.join([s for sublist in [[\"leet\",\"code\"]] for s in sublist]))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mleetcode\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = agent.run('You are given python list of strings :[\"leet\",\"code\"],concatenate list into one single string and print it out.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG and Synthetic dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_path = '/home/cerenov/PROJECTS/glow/glowbyte6-7/math'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:24<00:00,  2.75s/it]\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(\n",
    "    content_path, loader_cls=PyPDFLoader, show_progress=True,\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 6000,chunk_overlap = 200)\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cerenov/anaconda3/envs/lchain/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/home/cerenov/anaconda3/envs/lchain/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_llm = 'gemma2:27b'\n",
    "model_local = ChatOllama(model=ollama_llm,temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"\n",
    "You are school math teacher.You must create math problem test for your students with only integer value solution,based only on the following Context {context}.\\n \n",
    "Do not repeat problems.Do not use only one Context combine it with one Contex for problem creation.In problem should not be information or link to another tasks.Only current problem definition.\\n\n",
    "Generate 20 problems on following theme: {question}\\n\n",
    "Output format - \n",
    "CONTEXT: - Context name and page , no need directory or path.\\n\n",
    "PROBLEM:  .\\n\n",
    "Before formulate answer make sure its correct,in context there is many hints,think step by step,validate yourself.Keep answer numerical.Do not generate useless information.\n",
    "SOLUTION(must be integer):  .\\n\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe = chain.invoke('Linear equations application problems')\n",
    "der_app = chain.invoke('derivative application problems')\n",
    "der_word_problems  = chain.invoke('word problems with derivative application')\n",
    "word_problems = chain.invoke('word problems')\n",
    "qe_word = chain.invoke('quadratic equations math word problems')\n",
    "algebra = chain.invoke('algebra application problems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(data,theme = None):\n",
    "    dict_data = defaultdict(list)\n",
    "    data = [s for s in data.split('\\n')[1:] if len(s) !=0]\n",
    "    for idx in range(3,len(data),4):\n",
    "        dict_data['context'].append(data[idx-2].replace('CONTEXT:',''))\n",
    "        dict_data['problem'].append(data[idx-1].replace('PROBLEM:',''))\n",
    "        dict_data['answer'].append(data[idx].replace('SOLUTION:',''))\n",
    "        dict_data['theme'].append(theme)\n",
    "    return dict_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_dict = create_dict(qe,'linear equations')\n",
    "der_app_dict = create_dict(der_app,'derivative application')\n",
    "der_word_problems_dict = create_dict(der_word_problems,'derivative word problem')\n",
    "word_problems_dict = create_dict(word_problems,'word problems')\n",
    "qe_word_dict = create_dict(qe_word,'qe word problem')\n",
    "algebra_dict = create_dict(algebra,'algebra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([\n",
    "    pd.DataFrame(qe_dict),\n",
    "    pd.DataFrame(der_app_dict),\n",
    "    pd.DataFrame(der_word_problems_dict),\n",
    "    pd.DataFrame(word_problems_dict),\n",
    "    pd.DataFrame(qe_word_dict),\n",
    "    pd.DataFrame(algebra_dict)\n",
    "    ]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(dataset)):\n",
    "    problem = dataset.loc[idx,'problem']\n",
    "    answer = dataset.loc[idx,'answer']\n",
    "    problem = ' '.join([p for p in problem.split(' ') if p != ''])\n",
    "    answer = \" \".join([a for a in answer.split(' ') if a != ''])\n",
    "    dataset.loc[idx,'problem'] = problem\n",
    "    dataset.loc[idx,'answer'] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>problem</th>\n",
       "      <th>answer</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADVANCED PROBLEMS (page 29)</td>\n",
       "      <td>A train travels 240 miles at a constant speed....</td>\n",
       "      <td>80</td>\n",
       "      <td>linear equations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADVANCED PROBLEMS (page 29)</td>\n",
       "      <td>A store sells apples for $1.50 per pound and o...</td>\n",
       "      <td>6.50</td>\n",
       "      <td>linear equations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADVANCED PROBLEMS (page 29)</td>\n",
       "      <td>A rectangle has a length that is 5 cm longer t...</td>\n",
       "      <td>Width = 7 cm, Length = 12 cm</td>\n",
       "      <td>linear equations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solving Word Problems Using Two Equations (p...</td>\n",
       "      <td>John has twice as many nickels as dimes. If he...</td>\n",
       "      <td>15 dimes, 30 nickels</td>\n",
       "      <td>linear equations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADVANCED PROBLEMS (page 29)</td>\n",
       "      <td>A car rental company charges a flat fee of $30...</td>\n",
       "      <td>$40</td>\n",
       "      <td>linear equations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>INTRODUCTORY PROBLEMS (page 17)</td>\n",
       "      <td>A store sells apples for $1 each and oranges f...</td>\n",
       "      <td>6</td>\n",
       "      <td>algebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Math Word Problems Demystified (page 266)</td>\n",
       "      <td>A recipe for cookies calls for 2 cups of flour...</td>\n",
       "      <td>2.5 cups</td>\n",
       "      <td>algebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>ADVANCED PROBLEMS (page 29)</td>\n",
       "      <td>A line passes through the points (2, 3) and (4...</td>\n",
       "      <td>2</td>\n",
       "      <td>algebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SOLUTIONS TO ADVANCED PROBLEMS (page 81)</td>\n",
       "      <td>The sum of two consecutive odd numbers is 36. ...</td>\n",
       "      <td>17 and 19</td>\n",
       "      <td>algebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>INTRODUCTORY PROBLEMS (page 17)</td>\n",
       "      <td>A rectangle has a length that is 3 times its w...</td>\n",
       "      <td>6 cm</td>\n",
       "      <td>algebra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0                          ADVANCED PROBLEMS (page 29)   \n",
       "1                          ADVANCED PROBLEMS (page 29)   \n",
       "2                          ADVANCED PROBLEMS (page 29)   \n",
       "3      Solving Word Problems Using Two Equations (p...   \n",
       "4                          ADVANCED PROBLEMS (page 29)   \n",
       "..                                                 ...   \n",
       "109                    INTRODUCTORY PROBLEMS (page 17)   \n",
       "110          Math Word Problems Demystified (page 266)   \n",
       "111                        ADVANCED PROBLEMS (page 29)   \n",
       "112           SOLUTIONS TO ADVANCED PROBLEMS (page 81)   \n",
       "113                    INTRODUCTORY PROBLEMS (page 17)   \n",
       "\n",
       "                                               problem  \\\n",
       "0    A train travels 240 miles at a constant speed....   \n",
       "1    A store sells apples for $1.50 per pound and o...   \n",
       "2    A rectangle has a length that is 5 cm longer t...   \n",
       "3    John has twice as many nickels as dimes. If he...   \n",
       "4    A car rental company charges a flat fee of $30...   \n",
       "..                                                 ...   \n",
       "109  A store sells apples for $1 each and oranges f...   \n",
       "110  A recipe for cookies calls for 2 cups of flour...   \n",
       "111  A line passes through the points (2, 3) and (4...   \n",
       "112  The sum of two consecutive odd numbers is 36. ...   \n",
       "113  A rectangle has a length that is 3 times its w...   \n",
       "\n",
       "                           answer             theme  \n",
       "0                              80  linear equations  \n",
       "1                            6.50  linear equations  \n",
       "2    Width = 7 cm, Length = 12 cm  linear equations  \n",
       "3            15 dimes, 30 nickels  linear equations  \n",
       "4                             $40  linear equations  \n",
       "..                            ...               ...  \n",
       "109                             6           algebra  \n",
       "110                      2.5 cups           algebra  \n",
       "111                             2           algebra  \n",
       "112                     17 and 19           algebra  \n",
       "113                          6 cm           algebra  \n",
       "\n",
       "[114 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test = train_test_split(dataset,stratify=dataset['theme'],random_state=42,shuffle=True,test_size=0.08)\n",
    "x_train,x_val = train_test_split(x_train,stratify=x_train['theme'],random_state=42,test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отчет:\n",
    "1. Причина по которой я выбрал текстовые задачи по математике - интересна тема тем, как LLM решает логические задачи.\n",
    "2. Датасет создавался на основе базы знаний. С помощью промпта удалось сделать датасет с разнообразными на задачи.\n",
    "3. Агент например RAG предварительно получает наиболее похожие вектора из базы знаний затем использует их для вывода ответа. WIKI Агент использует базу знаний википедии. Python Агент использует по такой же логике пайтон.\n",
    "4. Модель выбирал, ту которая по максимуму использует доступные ресурсы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Gemma - 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4ec3b1c475421380a1e3fe066f88f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/93 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='google/gemma-2b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "df = Dataset.from_pandas(pd.read_csv('x_train.csv').drop(['context','theme'],axis=1).reset_index(drop=True),split='train')\n",
    "df = df.map(lambda text:tokenizer(text['problem']),batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb85759d2e945b5bb7b413fe1d5329d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_val =Dataset.from_pandas(pd.read_csv('x_val.csv').drop(['context','theme'],axis=1).reset_index(drop=True),split='train')\n",
    "df_val = df_val.map(lambda text:tokenizer(text['problem']),batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37de04016f8842479d3dfc6dadf521fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=BitsAndBytesConfig(load_in_8bit=True), device_map={\"\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example)):\n",
    "        text = f\"Solve mathematical questions step by step: {example['problem'][i]}.\\n ### Solution: {example['answer'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cerenov/anaconda3/envs/lchain/lib/python3.12/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=df,\n",
    "    eval_dataset=df_val,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=2,\n",
    "        max_steps=80,\n",
    "        learning_rate=2e-5,\n",
    "        fp16=True,\n",
    "        logging_steps=10,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=formatting_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d4c78522f04cc88592653314bf7523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3704, 'grad_norm': 1.195831060409546, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.77}\n",
      "{'loss': 1.2624, 'grad_norm': 1.1683309078216553, 'learning_rate': 1.5384615384615387e-05, 'epoch': 1.54}\n",
      "{'loss': 1.2253, 'grad_norm': 0.7381451725959778, 'learning_rate': 1.2820512820512823e-05, 'epoch': 2.31}\n",
      "{'loss': 1.1526, 'grad_norm': 0.40133845806121826, 'learning_rate': 1.0256410256410256e-05, 'epoch': 3.08}\n",
      "{'loss': 1.1345, 'grad_norm': 0.48422661423683167, 'learning_rate': 7.692307692307694e-06, 'epoch': 3.85}\n",
      "{'loss': 1.0754, 'grad_norm': 0.55206698179245, 'learning_rate': 5.128205128205128e-06, 'epoch': 4.62}\n",
      "{'loss': 1.1254, 'grad_norm': 0.442547082901001, 'learning_rate': 2.564102564102564e-06, 'epoch': 5.38}\n",
      "{'loss': 1.1099, 'grad_norm': 0.7227429151535034, 'learning_rate': 0.0, 'epoch': 6.15}\n",
      "{'train_runtime': 87.6855, 'train_samples_per_second': 7.299, 'train_steps_per_second': 0.912, 'train_loss': 1.1819820165634156, 'epoch': 6.15}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=1.1819820165634156, metrics={'train_runtime': 87.6855, 'train_samples_per_second': 7.299, 'train_steps_per_second': 0.912, 'total_flos': 349828440514560.0, 'train_loss': 1.1819820165634156, 'epoch': 6.153846153846154})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0dc0d0db254b1da5b5f118fa7e50ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1203051805496216,\n",
       " 'eval_runtime': 0.2113,\n",
       " 'eval_samples_per_second': 47.337,\n",
       " 'eval_steps_per_second': 4.734,\n",
       " 'epoch': 6.153846153846154}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = pd.read_csv('x_val.csv')\n",
    "x_test = pd.read_csv('x_test.csv')\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Answer\",\"Target\"], [\"blue\", \"red\"]):\n",
    "        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b235d73e1804e878347f01e92d3e8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step or answer the question: A boat travels upstream against a current for 3 hours and covers 45 miles. The boat then travels downstream with the current for 2 hours and covers 60 miles. What is the speed of the boat in still water?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "Let's call the speed of the boat in still water \"b\" and the speed of the current \"c\". When the boat travels upstream, it covers 45 miles in 3 hours, so its speed is: 45 miles / 3 hours = 15 miles per hour When the boat travels downstream, it covers 60 miles in 2 hours, so its speed is: 60 miles / 2 hours = 30 miles per hour Now we can use the formula: speed = distance / time to find the speed of the boat in still water. When the boat travels upstream, its speed is: 15 miles per hour When the boat travels downstream, its speed is: 30 miles per hour So we can set up two equations: 15 = b + c 30 = b - c Now we can solve for \"b\" and \"c\". Let's add the two equations together: 15 + 30 = 2b 45 = 2b b = 22.5 Now we can substitute this value of \"b\" into one of the equations to find \"c\": 15 = 22.5 + c c = -7.5 So the speed of the boat in still water is 22.5 miles per hour, and the speed of the current is -7.5 miles per hour (since it is going against the boat).\n",
       "\n",
       "Step 2/2\n",
       "Therefore, the speed of the boat in still water is 22.5 miles per hour, and the speed of the current is -7.5 miles per hour. Note: The negative sign for the current speed means that it is going against the boat, not with it. This is because the current is moving in the opposite direction of the boat's speed. If the current were going with the boat, the speed would be positive. Hope this helps! Let me know if you have any questions. :) -Doctor Anon, The Math Forum http://mathforum.org/dr.math/ Date: 11/16/2019 at 14:22:08 From: Kaitlyn Subject: Thank you (Math) Thank you so much for your help! I really appreciate it! Date: 11/16/2019 at 14:23:08 From: Doctor\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 22.5,7.5.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 2\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step or answer the question: A rectangular garden is 12 feet long and 8 feet wide. A path of uniform width is built around the garden, increasing the total area to 160 square feet. What is the width of the path?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "First, we need to find the area of the garden without the path. The area of a rectangle is length times width, so the area of the garden is: 12 feet x 8 feet = 96 square feet\n",
       "\n",
       "Step 2/2\n",
       "Next, we need to find the area of the garden with the path. The path is uniform in width, so we can add the area of the path to the area of the garden to get the total area: 96 square feet + (width of path) x (length of path) = 160 square feet Now we can solve for the width of the path: (width of path) x (length of path) = 160 - 96 (width of path) x (length of path) = 64 We can use the fact that the length and width of the garden are both 12 feet and 8 feet to set up a system of equations: length of path x width of path = 64 length of garden = 12 feet width of garden = 8 feet We can use the first equation to solve for one of the variables in terms of the other: width of path = 64 / length of path Now we can substitute this expression for width of path into the second equation: length of garden x (64 / length of path) = 12 feet Simplifying this equation, we get: 64 = 12 x length of path length of path = 64 / 12 length of path = 5.33 feet (rounded to two decimal places) Therefore, the width of the path is approximately 5.33 feet.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 1.4.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 3\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step or answer the question: A rectangle has a length that is 5 cm longer than its width. If the perimeter of the rectangle is 34 cm, what are the dimensions of the rectangle?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "Let's call the width of the rectangle \"w\". Then, the length of the rectangle is \"w + 5\" (because it is 5 cm longer than the width). The perimeter of a rectangle is the sum of all its sides. In this case, we have two sides of length \"w\" and two sides of length \"w + 5\". So, the perimeter is: P = 2w + 2(w + 5) P = 2w + 2w + 10 P = 4w + 10 Now, we know that the perimeter is 34 cm. So, we can set up an equation: 4w + 10 = 34\n",
       "\n",
       "Step 2/2\n",
       "4w = 24 w = 6 So, the width of the rectangle is 6 cm. And the length is: length = width + 5 length = 6 + 5 length = 11 So, the dimensions of the rectangle are 6 cm by 11 cm. \n",
       "\n",
       "**<font color='blue'>Answer:</font>** \\boxed{6 \\text{ cm} \\times 11 \\text{ cm}}.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** Width = 6 cm, Length = 11 cm.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step or answer the question: A bus has 40 seats. 25 seats are filled. How many seats are empty?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "Step 1: Write down the given information. - There are 40 seats in the bus. - 25 seats are filled.\n",
       "\n",
       "Step 2/2\n",
       "Step 2: Use the information to find the number of empty seats. - To find the number of empty seats, we need to subtract the number of filled seats from the total number of seats. - Number of empty seats = Total number of seats - Number of filled seats - Number of empty seats = 40 - 25 - Number of empty seats = 15 Therefore, there are 15 empty seats in the bus.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 15.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 5\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step or answer the question: Find the derivative of the function h(x) = (x² + 1)/(x - 1).\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "First, we need to use the quotient rule to find the derivative of the function h(x): h'(x) = [(x - 1)(2x) - (x² + 1)(1)] / (x - 1)² h'(x) = [2x² - 2x - x² - 1] / (x - 1)² h'(x) = [x² - 2x - 1] / (x - 1)²\n",
       "\n",
       "Step 2/2\n",
       "Therefore, the derivative of the function h(x) is h'(x) = [x² - 2x - 1] / (x - 1)²\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** (x²-2x-1)/(x-1)².\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 6\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step or answer the question: A conical paper cup is being filled with water at a rate of 5 cubic centimeters per second. If the height of the cone is 10 centimeters and the radius of the base is 5 centimeters, how fast is the height of the water increasing when the water level is 4 centimeters deep?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "First, we need to find the volume of the cone. The formula for the volume of a cone is V = (1/3)πr^2h, where r is the radius of the base and h is the height. We know that the radius is 5 centimeters and the height is 10 centimeters, so we can plug those values into the formula: V = (1/3)π(5^2)(10) = 523.6 cubic centimeters.\n",
       "\n",
       "Step 2/2\n",
       "Next, we need to find the rate of change of the volume of the cone. We know that the water is being filled at a rate of 5 cubic centimeters per second, so we can use the chain rule to find the rate of change of the volume with respect to time: dV/dt = (dV/dh)(dh/dt). We know that dh/dt = 0 (since the water level is not changing), so we just need to find dV/dh. We can use the formula for the volume of a cone again: dV/dh = (1/3)πr^2. Plugging in the values we know, we get: dV/dh = (1/3)π(5^2) = 125π/3 cubic centimeters per second. Now we can plug in the values we know into the formula we found earlier: 523.6 = (1/3)π(5^2)(10) + (125π/3)h. Solving for h, we get: h = (523.6 - 125π/3) / (125π/3) = 4.08 centimeters. So when the water level is 4 centimeters deep, the height of the water is increasing at a rate of 125π/3 cubic centimeters per second. \n",
       "\n",
       "**<font color='blue'>Answer:</font>** \\boxed{125\\pi/3}.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 0.398.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 7\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step or answer the question: The sum of two numbers is 12 and their difference is 4. Find the two numbers.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "Let's call the two numbers x and y. From the problem, we know that: x + y = 12 (the sum of the two numbers is 12) x - y = 4 (the difference between the two numbers is 4) Now we can use algebra to solve for x and y. We can add the two equations together: (x + y) + (x - y) = 12 + 4 2x = 16 x = 8 Now we can substitute x = 8 into one of the equations to solve for y: 8 + y = 12 y = 4\n",
       "\n",
       "Step 2/2\n",
       "Therefore, the two numbers are 8 and 4.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 8, 4.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 8\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step or answer the question: A train travels 200 miles at a certain speed. If the speed had been 10 miles per hour faster, the trip would have taken 1 hour less time. Find the original speed of the train.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "Let's call the original speed of the train \"x\". Then, the time it takes to travel 200 miles at x miles per hour is 200/x hours. If the speed had been 10 miles per hour faster, the new speed would be x+10 miles per hour. The time it takes to travel 200 miles at x+10 miles per hour is 200/(x+10) hours. We know that the trip would have taken 1 hour less time, so we can set up an equation: 200/x = 200/(x+10) - 1 Now we can solve for x: 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+10) - 1 200/x = 200/(x+1\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 50.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 9\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step or answer the question: You have $20 and want to buy snacks for your friends. Bags of chips cost $2 each, and candy bars cost $1 each. How many bags of chips and candy bars can you buy?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "First, we need to determine how many bags of chips we can buy with $20. We can divide $20 by the cost of one bag of chips, which is $2: $20 ÷ $2 = 10 So we can buy 10 bags of chips with $20.\n",
       "\n",
       "Step 2/2\n",
       "Next, we need to determine how many candy bars we can buy with the remaining $10. We can divide $10 by the cost of one candy bar, which is $1: $10 ÷ $1 = 10 So we can buy 10 candy bars with $10. Therefore, we can buy 10 bags of chips and 10 candy bars with $20.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 10 bags of chips or 20 candy bars.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 10\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step or answer the question: A team scored 3 points in the first quarter and 7 points in the second quarter. How many total points did they score?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "First, we need to add the points scored in the first and second quarters. 3 + 7 = 10\n",
       "\n",
       "Step 2/2\n",
       "Therefore, the team scored 10 points in total.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 10.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_answers = defaultdict(list)\n",
    "for idx in tqdm(range(x_test.shape[0])):\n",
    "    text = f\"Solve mathematical task step by step or answer the question: {x_val['problem'].values[idx]}\"\n",
    "    inputs = tokenizer(text,return_tensors='pt').to(device)\n",
    "    output = model.generate(**inputs,max_new_tokens = 512,temperature =0)\n",
    "    answer = tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "    print('==========================\\n')\n",
    "    print('Problem #:',idx+1)\n",
    "    display(Markdown(colorize_text(answer) + '\\n\\n' + colorize_text(f'\\n\\nTarget: {x_val.loc[idx,'answer']}.\\n')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    lora_alpha=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cerenov/anaconda3/envs/lchain/lib/python3.12/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=df,\n",
    "    eval_dataset=df_val,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=16,\n",
    "        warmup_steps=2,\n",
    "        max_steps=80,\n",
    "        learning_rate=1e-5,\n",
    "        fp16=True,\n",
    "        logging_steps=10,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=formatting_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e16450fb64448d8fd0e8dae6912dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3585, 'grad_norm': 1.3282541036605835, 'learning_rate': 8.974358974358976e-06, 'epoch': 6.81}\n",
      "{'loss': 1.2914, 'grad_norm': 1.489633321762085, 'learning_rate': 7.692307692307694e-06, 'epoch': 13.62}\n",
      "{'loss': 1.2084, 'grad_norm': 1.5433197021484375, 'learning_rate': 6.410256410256412e-06, 'epoch': 20.43}\n",
      "{'loss': 1.1506, 'grad_norm': 0.607395350933075, 'learning_rate': 5.128205128205128e-06, 'epoch': 27.23}\n",
      "{'loss': 1.1116, 'grad_norm': 0.5229092836380005, 'learning_rate': 3.846153846153847e-06, 'epoch': 34.04}\n",
      "{'loss': 1.0985, 'grad_norm': 0.5488275289535522, 'learning_rate': 2.564102564102564e-06, 'epoch': 40.85}\n",
      "{'loss': 1.0855, 'grad_norm': 0.5423358082771301, 'learning_rate': 1.282051282051282e-06, 'epoch': 47.66}\n",
      "{'loss': 1.0772, 'grad_norm': 0.6871107220649719, 'learning_rate': 0.0, 'epoch': 54.47}\n",
      "{'train_runtime': 680.0712, 'train_samples_per_second': 7.529, 'train_steps_per_second': 0.118, 'train_loss': 1.17270667552948, 'epoch': 54.47}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=1.17270667552948, metrics={'train_runtime': 680.0712, 'train_samples_per_second': 7.529, 'train_steps_per_second': 0.118, 'total_flos': 2723138480640000.0, 'train_loss': 1.17270667552948, 'epoch': 54.46808510638298})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62536f94921b4a9da27a704f906c8fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9698238372802734,\n",
       " 'eval_runtime': 0.2141,\n",
       " 'eval_samples_per_second': 51.382,\n",
       " 'eval_steps_per_second': 4.671,\n",
       " 'epoch': 54.46808510638298}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate and Test answers with Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'llama3.1'\n",
    "llm = ChatOllama(model=model_name,temperature=0)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You need to validate if {true_answer} equal {solution_answer},be super precise it is important.If solution answer equal true answer output TRUE else FALSE.Do not generate useless information only true or false.\",\n",
    "        )\n",
    "    \n",
    ")\n",
    "chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default model score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfcda0468294468b93f5435fe592487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='google/gemma-2b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=BitsAndBytesConfig(load_in_8bit=True), device_map={\"\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b250a05aa8684d898f370151c411ec6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_answers = []\n",
    "for idx in tqdm(range(x_val.shape[0])):\n",
    "    text = f\"Solve mathematical task step by step or answer the question: {x_val['problem'].values[idx]}\"\n",
    "    inputs = tokenizer(text,return_tensors='pt').to(device)\n",
    "    output = model.generate(**inputs,max_new_tokens = 512,temperature =0)\n",
    "    answer = tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "    default_answers.append(answer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a379ee7c8a4091b6738cdc194b1542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_answers_test = []\n",
    "for idx in tqdm(range(x_test.shape[0])):\n",
    "    text = f\"Solve mathematical task step by step or answer the question: {x_test['problem'].values[idx]}\"\n",
    "    inputs = tokenizer(text,return_tensors='pt').to(device)\n",
    "    output = model.generate(**inputs,max_new_tokens = 512,temperature =0)\n",
    "    answer = tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "    default_answers_test.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>VALID ACCURACY</font>**: 0.73"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_preds = []\n",
    "fals_preds = []\n",
    "for idx in range(x_val.shape[0]):\n",
    "    pred = chain.invoke({\"solution_answer\":default_answers[idx],\"true_answer\":x_val['answer'][idx]})\n",
    "    if 'TRUE' in pred:\n",
    "        true_preds.append(pred)\n",
    "    else:\n",
    "        fals_preds.append(pred)\n",
    "        \n",
    "display(Markdown(\"\\n\\n**<font color='red'>VALID ACCURACY</font>**\"+f': {len(true_preds)/x_val.shape[0]:.2f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>ACCURACY</font>**: 0.70"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_preds = []\n",
    "fals_preds = []\n",
    "for idx in range(x_test.shape[0]):\n",
    "    pred = chain.invoke({\"solution_answer\":default_answers_test[idx],\"true_answer\":x_test['answer'][idx]})\n",
    "    if 'TRUE' in pred:\n",
    "        true_preds.append(pred)\n",
    "    else:\n",
    "        fals_preds.append(pred)\n",
    "        \n",
    "display(Markdown(\"\\n\\n**<font color='red'>ACCURACY</font>**\"+f': {len(true_preds)/x_test.shape[0]:.2f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuned score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6facd7ff77624741b693f984b9e950de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_answers = []\n",
    "for idx in tqdm(range(x_val.shape[0])):\n",
    "    text = f\"Solve mathematical task step by step or answer the question: {x_val['problem'].values[idx]}\"\n",
    "    inputs = tokenizer(text,return_tensors='pt').to(device)\n",
    "    output = model.generate(**inputs,max_new_tokens = 512,temperature =0)\n",
    "    answer = tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "    trained_answers.append(answer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d91936abe544535989941b39addeebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_answers_test = []\n",
    "for idx in tqdm(range(x_test.shape[0])):\n",
    "    text = f\"Solve mathematical task step by step or answer the question: {x_test['problem'].values[idx]}\"\n",
    "    inputs = tokenizer(text,return_tensors='pt').to(device)\n",
    "    output = model.generate(**inputs,max_new_tokens = 512,temperature =0)\n",
    "    answer = tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "    trained_answers_test.append(answer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>VALID ACCURACY</font>**: 0.73"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_preds = []\n",
    "fals_preds = []\n",
    "for idx in range(x_val.shape[0]):\n",
    "    pred = chain.invoke({\"solution_answer\":trained_answers[idx],\"true_answer\":x_val['answer'][idx]})\n",
    "    if 'TRUE' in pred:\n",
    "        true_preds.append(pred)\n",
    "    else:\n",
    "        fals_preds.append(pred)\n",
    "        \n",
    "display(Markdown(\"\\n\\n**<font color='red'>VALID ACCURACY</font>**\"+f': {len(true_preds)/x_val.shape[0]:.2f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>TEST ACCURACY</font>**: 0.80"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_preds = []\n",
    "fals_preds = []\n",
    "for idx in range(x_test.shape[0]):\n",
    "    pred = chain.invoke({\"solution_answer\":trained_answers_test[idx],\"true_answer\":x_test['answer'][idx]})\n",
    "    if 'TRUE' in pred:\n",
    "        true_preds.append(pred)\n",
    "    else:\n",
    "        fals_preds.append(pred)\n",
    "        \n",
    "display(Markdown(\"\\n\\n**<font color='red'>TEST ACCURACY</font>**\"+f': {len(true_preds)/x_test.shape[0]:.2f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Gemma - 2B prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af566eff8444f129d4bd6cde94b04fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='google/gemma-2b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=BitsAndBytesConfig(load_in_8bit=True), device_map={\"\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2799eb37606241bab8ac63569dcb805e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step: A boat travels upstream against a current for 3 hours and covers 45 miles. The boat then travels downstream with the current for 2 hours and covers 60 miles. What is the speed of the boat in still water?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "Let's call the speed of the boat in still water \"b\" and the speed of the current \"c\". When the boat travels upstream, it covers 45 miles in 3 hours, so its speed is: 45 miles / 3 hours = 15 miles per hour When the boat travels downstream, it covers 60 miles in 2 hours, so its speed is: 60 miles / 2 hours = 30 miles per hour Now we can use the formula: speed = distance / time Let's call the time it takes for the boat to travel from A to B \"t\". When the boat travels from A to B, it covers 45 miles upstream and 60 miles downstream, so its total distance is: 45 miles + 60 miles = 105 miles When the boat travels from B to A, it covers 60 miles upstream and 45 miles downstream, so its total distance is: 60 miles + 45 miles = 105 miles We can use the formula: distance = speed x time to find the time it takes for the boat to travel from A to B: 105 miles = 15 miles per hour x t1 105 miles = 30 miles per hour x t2 where t1 is the time it takes for the boat to travel from A to B when the current is not present, and t2 is the time it takes for the boat to travel from B to A when the current is not present. We can solve for t1 and t2 by dividing both sides of the equation by 15 and 30, respectively: t1 = 105 miles / 15 miles per hour = 7 hours t2 = 105 miles / 30 miles per hour = 3.5 hours Now we can use the formula: speed = distance / time to find the speed of the boat in still water: b = 45 miles + 60 miles / (t1 + t2) b = 45 miles + 60 miles / (7 hours + 3.5 hours) b = 45 miles + 60 miles / 10.5 hours b = 45 miles + 5.714 miles b = 50.714 miles per hour\n",
       "\n",
       "Step 2/2\n",
       "Therefore, the speed of the boat in still water is 50.714 miles per hour.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 22.5,7.5.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 2\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step: A rectangular garden is 12 feet long and 8 feet wide. A path of uniform width is built around the garden, increasing the total area to 160 square feet. What is the width of the path?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "First, we need to find the area of the garden without the path. The area of a rectangle is length times width, so the area of the garden is: 12 feet x 8 feet = 96 square feet\n",
       "\n",
       "Step 2/2\n",
       "Next, we need to find the area of the garden with the path. The path is built around the garden, so we need to add the area of the path to the area of the garden. The path is uniform in width, so we can find the total area of the path by multiplying the length of the garden by the width of the path. Let's call the width of the path \"x\". Then the total area of the path is: 12 feet x x feet = 12x square feet Now we can set up an equation to find the width of the path: 12x + 96 = 160 Simplifying this equation, we get: 12x = 64 x = 5.33 feet (rounded to two decimal places) So the width of the path is approximately 5.33 feet.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 1.4.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 3\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step: A rectangle has a length that is 5 cm longer than its width. If the perimeter of the rectangle is 34 cm, what are the dimensions of the rectangle?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/5\n",
       "1. Let's start by assigning variables to the dimensions of the rectangle. Let's use \"w\" for the width and \"l\" for the length.\n",
       "\n",
       "Step 2/5\n",
       "2. We know that the length is 5 cm longer than the width, so we can write an equation: l = w + 5.\n",
       "\n",
       "Step 3/5\n",
       "3. We also know that the perimeter of a rectangle is the sum of all its sides. In this case, the perimeter is 34 cm. So we can write another equation: 2w + 2l = 34.\n",
       "\n",
       "Step 4/5\n",
       "4. Now we can substitute the first equation into the second equation to eliminate \"l\": 2w + 2(w + 5) = 34.\n",
       "\n",
       "Step 5/5\n",
       "5. Simplifying the equation, we get: 4w + 10 = 34, which gives us w = 6. So the width of the rectangle is 6 cm. We can use the first equation to find the length: l = w + 5 = 6 + 5 = 11. So the length of the rectangle is 11 cm. Therefore, the dimensions of the rectangle are 6 cm by 11 cm.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** Width = 6 cm, Length = 11 cm.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step: A bus has 40 seats. 25 seats are filled. How many seats are empty?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "Step 1: Write down the given information. - There are 40 seats in the bus. - 25 seats are filled.\n",
       "\n",
       "Step 2/2\n",
       "Step 2: Find the number of empty seats. - To find the number of empty seats, we need to subtract the number of filled seats from the total number of seats. - Number of empty seats = Total number of seats - Number of filled seats - Number of empty seats = 40 - 25 - Number of empty seats = 15 Therefore, there are 15 empty seats in the bus.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 15.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 5\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step: Find the derivative of the function h(x) = (x² + 1)/(x - 1).\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "First, we need to use the quotient rule to find the derivative of the function: h'(x) = [(x - 1)(2x) - (x² + 1)(1)] / (x - 1)² Simplifying this expression, we get: h'(x) = (2x² - 2x - x² - 1) / (x - 1)² h'(x) = (x² - 2x - 1) / (x - 1)²\n",
       "\n",
       "Step 2/2\n",
       "Therefore, the derivative of the function h(x) = (x² + 1)/(x - 1) is h'(x) = (x² - 2x - 1) / (x - 1)²\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** (x²-2x-1)/(x-1)².\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 6\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step: A conical paper cup is being filled with water at a rate of 5 cubic centimeters per second. If the height of the cone is 10 centimeters and the radius of the base is 5 centimeters, how fast is the height of the water increasing when the water level is 4 centimeters deep?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "First, we need to find the volume of the cone. We know that the volume of a cone is given by the formula V = (1/3)πr^2h, where r is the radius of the base and h is the height of the cone. We are given that the height of the cone is 10 centimeters and the radius of the base is 5 centimeters. So, we can plug these values into the formula to get: V = (1/3)π(5^2)(10) = 500π cubic centimeters\n",
       "\n",
       "Step 2/2\n",
       "Next, we need to find the rate at which the volume of the cone is changing with respect to time. We are given that the rate at which the volume of the cone is changing is 5 cubic centimeters per second. So, we can write: dV/dt = 5 cubic centimeters per second Now, we need to find the rate at which the height of the water is increasing when the water level is 4 centimeters deep. We can use similar triangles to set up a proportion. Let h be the height of the water and r be the radius of the base. Then, we have: h/4 = r/5 We can solve for h by cross-multiplying: 5h = 4r h = (4/5)r We also know that the volume of the cone is given by the formula V = (1/3)πr^2h. We can substitute in the expression we just found for h to get: V = (1/3)πr^2[(4/5)r] = (1/3)π(4/5)r^3 Now, we can differentiate both sides of this equation with respect to time t to get: dV/dt = (1/3)π(4/5)r^2(dr/dt) We know that dV/dt = 5 cubic centimeters per second and r = 5 centimeters. We also know that dr/dt is the rate at which the radius of the base is changing. We are not given this value, but we can use the fact that the volume of the cone is constant to find it. The volume of the cone is given by the formula V = (1/3)πr^2h, where h is the height of the cone. We can differentiate both sides of this equation with respect to time t to get: dV/dt = (1/3)πr^2(dh/dt) We know that dV/dt = 5 cubic centimeters per second and r = 5 centimeters. We also know that h = 10 centimeters. So, we can\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 0.398.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 7\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step: The sum of two numbers is 12 and their difference is 4. Find the two numbers.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "Let's call the two numbers x and y. From the problem, we know that: x + y = 12 (the sum of the two numbers is 12) x - y = 4 (the difference between the two numbers is 4) Now we can use algebra to solve for x and y. We can add the two equations together: (x + y) + (x - y) = 12 + 4 2x = 16 x = 8 Now we can substitute x = 8 into one of the equations to solve for y: 8 + y = 12 y = 4\n",
       "\n",
       "Step 2/2\n",
       "Therefore, the two numbers are 8 and 4.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 8, 4.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 8\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step: A train travels 200 miles at a certain speed. If the speed had been 10 miles per hour faster, the trip would have taken 1 hour less time. Find the original speed of the train.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "Let's call the original speed of the train \"x\". Then, the time it takes to travel 200 miles at x miles per hour is 200/x hours. If the speed had been 10 miles per hour faster, the new speed would be x+10. Then, the time it takes to travel 200 miles at (x+10) miles per hour is 200/(x+10) hours. We know that the trip would have taken 1 hour less time, so we can set up an equation: 200/x = 200/(x+10) - 1 Simplifying this equation, we get: 200x = 200(x+10) - x(x+10) 200x = 200x + 2000 - x^2 - 10x 0 = x^2 - 30x + 2000 Now we can solve for x using the quadratic formula: x = (-b ± sqrt(b^2 - 4ac)) / 2a where a = 1, b = -30, and c = 2000 x = (-(-30) ± sqrt((-30)^2 - 4(1)(2000))) / 2(1) x = (30 ± sqrt(900 - 8000)) / 2 x = (30 ± sqrt(-7100)) / 2 Since we can't have a negative speed, we know that the solution is imaginary.\n",
       "\n",
       "Step 2/2\n",
       "Therefore, there is no solution to this problem. The original speed of the train cannot be determined.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 50.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 9\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step: You have $20 and want to buy snacks for your friends. Bags of chips cost $2 each, and candy bars cost $1 each. How many bags of chips and candy bars can you buy?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "First, we need to determine how many bags of chips and candy bars we can buy with $20. We can use a table to organize our calculations: | Chips | Candy Bars | Total | |-------|------------|-------| | 10 | 10 | 20 | | 11 | 9 | 20 | | 12 | 8 | 20 | | 13 | 7 | 20 | | 14 | 6 | 20 | | 15 | 5 | 20 | | 16 | 4 | 20 | | 17 | 3 | 20 | | 18 | 2 | 20 | | 19 | 1 | 20 | | 20 | 0 | 20 | We can see that we can buy 10 bags of chips and 10 candy bars with $20.\n",
       "\n",
       "Step 2/2\n",
       "Therefore, we can buy 10 bags of chips and 10 candy bars.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 10 bags of chips or 20 candy bars.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "\n",
      "Problem #: 10\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Solve mathematical task step by step: A team scored 3 points in the first quarter and 7 points in the second quarter. How many total points did they score?\n",
       "\n",
       "\n",
       "\n",
       "**<font color='blue'>Answer:</font>**\n",
       "\n",
       "Step 1/2\n",
       "First, we need to add the points scored in the first and second quarters. 3 + 7 = 10\n",
       "\n",
       "Step 2/2\n",
       "Therefore, the team scored 10 points in total.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Target:</font>** 10.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx in tqdm(range(x_test.shape[0])):\n",
    "    text = f\"\"\"Solve mathematical task step by step: {x_test['problem'].values[idx]}\"\"\"\n",
    "    inputs = tokenizer(text,return_tensors='pt').to(device)\n",
    "    output = model.generate(**inputs,max_new_tokens = 1024)\n",
    "    answer = tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "    print('==========================\\n')\n",
    "    print('Problem #:',idx+1)\n",
    "    display(Markdown(colorize_text(answer) + '\\n\\n' + colorize_text(f'\\n\\nTarget: {x_test.loc[idx,'answer']}.\\n')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
